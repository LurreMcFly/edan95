{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab session 6\n",
    "\n",
    "In and after this lab session you will\n",
    "\n",
    "    - train a Gaussian NBC with the EM algorithm\n",
    "    - compare the results you get to those of the k-Means clustering provided in SciKitLearn\n",
    "    - discuss the classifiers from this lab session and those from the previous session (supervised learning of NBCs) in a \n",
    "    brief report\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import MNIST dataset from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported  1797  number of images from MNIST dataset\n",
      "Split into a 70/30 ratio between train and test set\n",
      "Number of training data  (1257, 64)\n",
      "Number of test data  (540, 64)\n"
     ]
    }
   ],
   "source": [
    "mnist = load_digits()\n",
    "print(\"Imported \", len(mnist.data), \" number of images from MNIST dataset\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(mnist.data, mnist.target,test_size = 0.3)\n",
    "\n",
    "print(\"Split into a 70/30 ratio between train and test set\")\n",
    "print(\"Number of training data \", x_train.shape)\n",
    "print(\"Number of test data \", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the EM-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "from numpy import linalg as npl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS IS NOT NAIVE!\n",
    "\n",
    "class EM_alg():\n",
    "    def __init__(self, n_clusters, epsilon = 1e-7):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.mu = {}\n",
    "        self.std = {}\n",
    "        self.p_C = {}\n",
    "        self.eps = epsilon\n",
    "        self.n_features = 0\n",
    "        self.r = {}\n",
    "        self.N = 0\n",
    "\n",
    "    \n",
    "    def log_prob(self, x, label):\n",
    "        prob = np.sum(-1/2*np.log(npl.det(self.std[label])+self.eps) - \\\n",
    "                1/2*np.inner(x-self.mu[label],np.matmul(npl.pinv(self.std[label] + np.eye(self.n_features)*self.eps),x-self.mu[label])))\n",
    "        return prob\n",
    "        \n",
    "        \n",
    "    \n",
    "    def E_step(self, X):\n",
    "        for point in range(self.N):\n",
    "       # for label in range(self.n_clusters):\n",
    "            self.r[label] = np.zeros(self.N)\n",
    "            nominator = np.sum([np.log(self.p_C[k] + self.eps)+self.log_prob(X[point,:],k) for k in range(self.n_clusters)])\n",
    "            # for point in range(self.N):\n",
    "            for label in range(self.n_clusters):\n",
    "                nominator = np.sum([self.p_C[k]*+np.exp(elf.log_prob(X[point,:],k)) for k in range(self.n_clusters)])\n",
    "                self.r[label][point] = self.p_C[label]*np.exp(self.log_prob(X[point,:],label))/nominator\n",
    "            \n",
    "        \n",
    "    def M_step(self, X):\n",
    "        for label in range(self.n_clusters):\n",
    "            r_k = np.sum([self.r[label][i] for i in range(self.N)])\n",
    "            self.p_C[label] = r_k/self.N\n",
    "            self.mu[label] = np.sum([self.r[label][i]*X[i] for i in range(self.N)],axis = 0)/r_k\n",
    "            top = np.zeros((self.n_features,self.n_features))\n",
    "            for i in range(self.N):\n",
    "                top += self.r[label][i]*X[i,:]*np.transpose(X[i,:])\n",
    "            self.std[label] = top/r_k - np.outer(self.mu[label],self.mu[label])\n",
    "        \n",
    "\n",
    "    def fit(self, X):    \n",
    "        self.n_features = X.shape[1]\n",
    "        self.N = X.shape[0]\n",
    "        for label in range(self.n_clusters):\n",
    "            self.mu[label] = np.random.rand(self.n_features)*np.max(X)\n",
    "            self.std[label] = np.diag(np.random.rand(self.n_features))\n",
    "            \n",
    "            self.p_C[label]= 1/self.n_clusters\n",
    "            \n",
    "        for i in range(10):\n",
    "            self.E_step(X)\n",
    "            self.M_step(X)\n",
    "                    \n",
    "            \n",
    "    def predict(self, X_new):\n",
    "        yhat = np.zeros(X_new.shape[0])\n",
    "        for point in range(X_new.shape[0]):\n",
    "            yhat[point] = np.argmax([np.log(self.p_C[k] + self.eps)+self.log_prob(X_new[point,:],k) for k in range(self.n_clusters)])\n",
    "\n",
    "        return yhat\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "em = EM_alg(10)\n",
    "em.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "em.mu\n",
    "predictions = em.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix own GNB:\n",
      "[[  0   6   0  35   0  83   0   0  11   1]\n",
      " [  8   3  67   8   2  10   2   0  28   0]\n",
      " [  0   3   0  46   2   2  60   3  13   2]\n",
      " [  0   7   0 117   1   0   0   0   0   2]\n",
      " [  0   1  26   0   0  90   0   0   1   2]\n",
      " [  1  14  46  44   2   9   0   1   1   1]\n",
      " [  0   0   1   0   1  75   0   0  50   0]\n",
      " [  1   0  49  23   0   3  18   1   8  32]\n",
      " [  1   6  25  28   7  19   5   0  10  12]\n",
      " [  0   3   0  98   1   1   2   0  11   5]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix own GNB:\\n%s\" % metrics.confusion_matrix(y_train, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class own_KMeans():\n",
    "    def __init__(self, n_clusters, epsilon = 1e-5):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.eps = epsilon\n",
    "        self.p_C = {}\n",
    "        self.mu = {}\n",
    "    \n",
    "    def E_step(self, X):\n",
    "        for i,x in enumerate(X):\n",
    "            self.y[i] = np.argmin([npl.norm(x-self.mu[label]) for label in range(self.n_clusters)])\n",
    "       \n",
    "    def M_step(self, X):\n",
    "        for label in range(self.n_clusters):\n",
    "            Ci = self.y == label\n",
    "            if sum(np.array(Ci)) != 0:\n",
    "                self.mu[label] = np.sum(X[Ci,:], axis = 0)/sum(np.array(Ci))\n",
    "      \n",
    "\n",
    "    def fit(self, X):\n",
    "        self.y = np.zeros(X.shape[0]) \n",
    "        for label in range(self.n_clusters):\n",
    "            self.p_C[label] = 1/self.n_clusters\n",
    "            self.mu[label] = np.random.rand(X.shape[1])*np.max(X)\n",
    "        \n",
    "        for i in range(10):\n",
    "            self.E_step(X)\n",
    "            self.M_step(X)\n",
    "            \n",
    "    def get_labels(self):\n",
    "        return self.y\n",
    "            \n",
    "    def predict(self,X_new):\n",
    "        yhat = np.zeros(X_new.shape[0])\n",
    "        for i,x in enumerate(X_new):\n",
    "            yhat[i] = np.argmin([npl.norm(x-self.mu[label]) for label in range(self.n_clusters)])\n",
    "        \n",
    "        return yhat\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "own_kmeans = own_KMeans(10)\n",
    "own_kmeans.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# own_kmeans.mu\n",
    "predictions = own_kmeans.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 4, 6, ..., 8, 0, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix own GNB:\n",
      "[[ 69   0   0   0   0   0  66   0   0   1]\n",
      " [  0   0   2  35   1  20   0   0  70   0]\n",
      " [  0   0   0   0   7 109   0  10   5   0]\n",
      " [  0   0   0   1   4   0   0 115   7   0]\n",
      " [  0   0   0   0   5   0   0   0   2 113]\n",
      " [  0   0   0  19   0   0   0  43  56   1]\n",
      " [  0   0 126   0   0   0   0   0   1   0]\n",
      " [  0   0   0   4 125   0   0   0   6   0]\n",
      " [  0   0   1  14   2   2   0  29  65   0]\n",
      " [  0   0   0  19   3   0   0  97   2   0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix own GNB:\\n%s\" % metrics.confusion_matrix(y_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLearn K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import BayesianGaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10).fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels from the kmeans algorithm:  [9 3 6 ... 1 5 6]\n",
      "Lables in y_train:  [9 8 5 ... 1 0 9]\n",
      "Cluster centers for the kmeans alg:  [[ 0.00000000e+00  5.52000000e-01  8.15200000e+00  1.42800000e+01\n",
      "   1.41440000e+01  7.17600000e+00  3.84000000e-01 -2.35922393e-16\n",
      "   1.60000000e-02  4.17600000e+00  1.27520000e+01  9.09600000e+00\n",
      "   1.10000000e+01  1.21840000e+01  1.66400000e+00 -1.38777878e-17\n",
      "   8.00000000e-03  2.32800000e+00  4.26400000e+00  3.56800000e+00\n",
      "   1.16320000e+01  9.68800000e+00  7.76000000e-01  9.02056208e-17\n",
      "  -1.62630326e-18  2.00000000e-01  9.84000000e-01  7.88000000e+00\n",
      "   1.38880000e+01  6.31200000e+00  2.64000000e-01 -3.25260652e-18\n",
      "   0.00000000e+00  8.80000000e-02  5.20000000e-01  4.00800000e+00\n",
      "   1.15440000e+01  1.19280000e+01  2.33600000e+00  0.00000000e+00\n",
      "  -1.90819582e-17  4.96000000e-01  1.41600000e+00  4.80000000e-01\n",
      "   4.02400000e+00  1.20400000e+01  6.58400000e+00  5.20417043e-17\n",
      "  -2.60208521e-17  8.16000000e-01  7.01600000e+00  6.49600000e+00\n",
      "   8.12000000e+00  1.30880000e+01  6.34400000e+00  1.44000000e-01\n",
      "   0.00000000e+00  4.48000000e-01  9.00800000e+00  1.48880000e+01\n",
      "   1.40560000e+01  8.98400000e+00  2.16000000e+00  3.76000000e-01]\n",
      " [ 0.00000000e+00  9.01639344e-01  1.01147541e+01  1.45327869e+01\n",
      "   7.87704918e+00  1.06557377e+00 -1.33226763e-15 -2.22044605e-16\n",
      "   1.63934426e-02  5.34426230e+00  1.37868852e+01  1.27213115e+01\n",
      "   1.17131148e+01  3.38524590e+00  4.88498131e-15 -1.38777878e-17\n",
      "   1.63934426e-02  4.68852459e+00  8.27049180e+00  5.97540984e+00\n",
      "   1.23606557e+01  3.67213115e+00 -3.55271368e-15  9.02056208e-17\n",
      "  -1.62630326e-18  9.59016393e-01  2.64754098e+00  6.81967213e+00\n",
      "   1.29180328e+01  2.43442623e+00 -2.22044605e-15 -3.25260652e-18\n",
      "   0.00000000e+00  5.73770492e-02  1.44262295e+00  9.83606557e+00\n",
      "   1.09016393e+01  1.43442623e+00 -6.66133815e-15  0.00000000e+00\n",
      "  -1.73472348e-17  1.14754098e-01  4.21311475e+00  1.14754098e+01\n",
      "   8.06557377e+00  2.67213115e+00  1.04098361e+00  1.63934426e-02\n",
      "  -2.60208521e-17  9.34426230e-01  1.09918033e+01  1.39754098e+01\n",
      "   1.24180328e+01  1.17786885e+01  7.88524590e+00  1.08196721e+00\n",
      "   0.00000000e+00  8.85245902e-01  1.04016393e+01  1.45901639e+01\n",
      "   1.32131148e+01  1.16639344e+01  8.58196721e+00  2.86885246e+00]\n",
      " [ 0.00000000e+00  5.55111512e-17  1.06400000e+00  1.11280000e+01\n",
      "   9.33600000e+00  1.52000000e+00  6.40000000e-02 -2.35922393e-16\n",
      "  -1.30104261e-17  6.40000000e-02  6.96800000e+00  1.45440000e+01\n",
      "   6.21600000e+00  8.64000000e-01  6.40000000e-02 -1.38777878e-17\n",
      "   4.33680869e-18  7.36000000e-01  1.21840000e+01  9.52000000e+00\n",
      "   9.84000000e-01  1.36000000e-01 -3.55271368e-15  9.02056208e-17\n",
      "  -1.62630326e-18  2.25600000e+00  1.33840000e+01  8.26400000e+00\n",
      "   4.01600000e+00  2.12800000e+00  1.28000000e-01 -3.25260652e-18\n",
      "   0.00000000e+00  3.36000000e+00  1.45120000e+01  1.25040000e+01\n",
      "   1.18000000e+01  1.03280000e+01  2.83200000e+00  0.00000000e+00\n",
      "  -1.90819582e-17  1.87200000e+00  1.43360000e+01  1.08960000e+01\n",
      "   5.63200000e+00  1.01120000e+01  9.14400000e+00  2.48000000e-01\n",
      "  -2.60208521e-17  2.08000000e-01  1.02080000e+01  1.26240000e+01\n",
      "   5.24000000e+00  1.13840000e+01  1.09120000e+01  6.00000000e-01\n",
      "   0.00000000e+00  0.00000000e+00  1.34400000e+00  1.06880000e+01\n",
      "   1.50960000e+01  1.32080000e+01  4.56800000e+00  1.12000000e-01]\n",
      " [ 0.00000000e+00  1.33757962e-01  4.05095541e+00  1.20191083e+01\n",
      "   1.24522293e+01  5.31210191e+00  4.64968153e-01 -2.08166817e-16\n",
      "   1.27388535e-02  9.93630573e-01  8.49681529e+00  1.35987261e+01\n",
      "   1.25859873e+01  9.78343949e+00  1.52866242e+00  0.00000000e+00\n",
      "   4.77048956e-18  1.42038217e+00  8.26114650e+00  1.18025478e+01\n",
      "   1.25159236e+01  9.24203822e+00  9.36305732e-01  1.04083409e-16\n",
      "  -1.84314369e-18  1.06369427e+00  7.04458599e+00  1.41847134e+01\n",
      "   1.40955414e+01  4.57961783e+00  1.21019108e-01 -3.68628739e-18\n",
      "   0.00000000e+00  7.32484076e-01  8.00636943e+00  1.49808917e+01\n",
      "   1.28343949e+01  2.23566879e+00  2.54777070e-02  0.00000000e+00\n",
      "  -3.64291930e-17  1.18471338e+00  1.02802548e+01  1.18407643e+01\n",
      "   1.26305732e+01  4.50955414e+00  2.48407643e-01  7.63278329e-17\n",
      "  -8.67361738e-18  8.08917197e-01  9.12101911e+00  1.12165605e+01\n",
      "   1.23121019e+01  6.07006369e+00  7.00636943e-01  6.36942675e-03\n",
      "   0.00000000e+00  1.08280255e-01  4.08917197e+00  1.22547771e+01\n",
      "   1.30445860e+01  4.75796178e+00  7.70700637e-01  1.27388535e-02]\n",
      " [ 0.00000000e+00  5.55111512e-17  3.07692308e-02  1.73846154e+00\n",
      "   1.11692308e+01  1.20923077e+01  3.70769231e+00  6.15384615e-02\n",
      "  -5.20417043e-18  6.15384615e-02  1.81538462e+00  8.67692308e+00\n",
      "   1.38307692e+01  1.24923077e+01  5.10769231e+00  1.53846154e-01\n",
      "   3.03576608e-18  1.70769231e+00  8.10769231e+00  1.24307692e+01\n",
      "   1.16461538e+01  1.27384615e+01  3.96923077e+00  7.69230769e-02\n",
      "  -6.50521303e-19  3.58461538e+00  1.23076923e+01  1.15076923e+01\n",
      "   1.26923077e+01  1.35846154e+01  2.38461538e+00 -1.30104261e-18\n",
      "   0.00000000e+00  2.44615385e+00  7.69230769e+00  8.04615385e+00\n",
      "   1.24461538e+01  1.27384615e+01  2.06153846e+00  0.00000000e+00\n",
      "   5.20417043e-18  6.00000000e-01  1.63076923e+00  3.64615385e+00\n",
      "   1.15538462e+01  1.23538462e+01  1.47692308e+00 -4.16333634e-17\n",
      "   0.00000000e+00  4.61538462e-02  2.61538462e-01  3.06153846e+00\n",
      "   1.21846154e+01  1.20153846e+01  1.80000000e+00  8.32667268e-17\n",
      "   0.00000000e+00  0.00000000e+00 -2.66453526e-15  1.83076923e+00\n",
      "   1.18615385e+01  1.09538462e+01  1.66153846e+00  2.77555756e-16]\n",
      " [ 0.00000000e+00  3.07692308e-02  4.09230769e+00  1.31307692e+01\n",
      "   1.09923077e+01  2.80769231e+00  2.30769231e-02 -2.63677968e-16\n",
      "  -1.30104261e-17  9.61538462e-01  1.27461538e+01  1.33153846e+01\n",
      "   1.16615385e+01  1.11307692e+01  7.76923077e-01 -1.38777878e-17\n",
      "   4.33680869e-18  3.83076923e+00  1.41153846e+01  5.20000000e+00\n",
      "   2.24615385e+00  1.24076923e+01  3.28461538e+00  9.02056208e-17\n",
      "  -1.62630326e-18  5.45384615e+00  1.24923077e+01  2.11538462e+00\n",
      "   1.53846154e-01  9.20769231e+00  6.42307692e+00 -3.25260652e-18\n",
      "   0.00000000e+00  5.96153846e+00  1.14307692e+01  9.00000000e-01\n",
      "   3.07692308e-02  8.65384615e+00  7.16923077e+00  0.00000000e+00\n",
      "  -2.25514052e-17  3.45384615e+00  1.33538462e+01  1.63846154e+00\n",
      "   1.31538462e+00  1.10846154e+01  5.94615385e+00  5.55111512e-17\n",
      "  -2.25514052e-17  7.23076923e-01  1.30769231e+01  9.99230769e+00\n",
      "   1.01461538e+01  1.34769231e+01  2.69230769e+00  3.07692308e-02\n",
      "   0.00000000e+00  0.00000000e+00  4.05384615e+00  1.36230769e+01\n",
      "   1.35384615e+01  5.73846154e+00  3.07692308e-01  2.30769231e-02]\n",
      " [ 0.00000000e+00  1.88235294e-01  6.92941176e+00  1.28647059e+01\n",
      "   1.17647059e+01  5.50000000e+00  5.23529412e-01 -1.11022302e-16\n",
      "   5.88235294e-03  2.69411765e+00  1.41117647e+01  9.20000000e+00\n",
      "   9.34117647e+00  9.64705882e+00  1.07058824e+00  1.38777878e-16\n",
      "   4.77048956e-18  4.27647059e+00  1.30529412e+01  4.36470588e+00\n",
      "   6.75882353e+00  1.06352941e+01  1.86470588e+00  1.04083409e-16\n",
      "  -7.58941521e-19  2.54705882e+00  1.10176471e+01  1.19823529e+01\n",
      "   1.28764706e+01  1.20529412e+01  2.62941176e+00 -1.51788304e-18\n",
      "   0.00000000e+00  5.29411765e-01  3.87647059e+00  6.64117647e+00\n",
      "   6.82941176e+00  1.14411765e+01  4.52941176e+00  0.00000000e+00\n",
      "  -4.16333634e-17  2.23529412e-01  2.39411765e+00  2.03529412e+00\n",
      "   1.68823529e+00  1.12823529e+01  6.32941176e+00  2.35294118e-02\n",
      "  -3.46944695e-18  8.88235294e-01  7.90588235e+00  5.16470588e+00\n",
      "   4.87647059e+00  1.29352941e+01  5.41764706e+00  7.64705882e-02\n",
      "   0.00000000e+00  1.64705882e-01  6.75294118e+00  1.38058824e+01\n",
      "   1.43647059e+01  9.42941176e+00  1.74705882e+00  2.35294118e-02]\n",
      " [ 0.00000000e+00  5.55111512e-17  2.90598291e-01  7.18803419e+00\n",
      "   1.18632479e+01  2.00000000e+00  2.13675214e-01  7.69230769e-02\n",
      "  -1.21430643e-17  8.54700855e-03  3.08547009e+00  1.38974359e+01\n",
      "   8.49572650e+00  1.77777778e+00  1.01709402e+00  2.82051282e-01\n",
      "   4.33680869e-18  5.98290598e-01  1.06923077e+01  1.15811966e+01\n",
      "   4.65811966e+00  5.37606838e+00  3.41025641e+00  2.64957265e-01\n",
      "   8.54700855e-03  4.72649573e+00  1.47521368e+01  5.74358974e+00\n",
      "   7.35897436e+00  1.02735043e+01  5.77777778e+00  1.70940171e-02\n",
      "   0.00000000e+00  8.93162393e+00  1.46837607e+01  9.27350427e+00\n",
      "   1.30683761e+01  1.42649573e+01  5.58119658e+00  0.00000000e+00\n",
      "   1.11111111e-01  7.00854701e+00  1.20683761e+01  1.27777778e+01\n",
      "   1.50341880e+01  1.06581197e+01  1.66666667e+00  4.51028104e-17\n",
      "   8.54700855e-02  1.25641026e+00  3.00854701e+00  7.89743590e+00\n",
      "   1.40769231e+01  3.84615385e+00  1.70940171e-02 -2.49800181e-16\n",
      "   0.00000000e+00  3.41880342e-02  3.24786325e-01  7.87179487e+00\n",
      "   1.24957265e+01  1.73504274e+00  3.55271368e-15  1.66533454e-16]\n",
      " [ 0.00000000e+00  1.27368421e+00  1.04947368e+01  1.35157895e+01\n",
      "   1.40210526e+01  1.26526316e+01  4.80000000e+00  4.21052632e-02\n",
      "   1.05263158e-02  5.04210526e+00  1.49894737e+01  1.28947368e+01\n",
      "   9.14736842e+00  7.37894737e+00  2.64210526e+00  3.15789474e-02\n",
      "   3.90312782e-18  6.52631579e+00  1.48105263e+01  6.18947368e+00\n",
      "   1.89473684e+00  8.31578947e-01  1.57894737e-01  6.93889390e-17\n",
      "  -1.30104261e-18  5.20000000e+00  1.45368421e+01  1.26947368e+01\n",
      "   7.31578947e+00  1.54736842e+00  1.05263158e-01 -2.60208521e-18\n",
      "   0.00000000e+00  1.73684211e+00  7.74736842e+00  1.03789474e+01\n",
      "   1.05789474e+01  4.55789474e+00  2.10526316e-01  0.00000000e+00\n",
      "   5.20417043e-18  3.78947368e-01  1.38947368e+00  5.40000000e+00\n",
      "   1.08736842e+01  6.03157895e+00  2.52631579e-01  1.73472348e-17\n",
      "  -1.73472348e-17  9.89473684e-01  5.68421053e+00  1.04736842e+01\n",
      "   1.21368421e+01  4.06315789e+00  1.05263158e-01 -2.77555756e-17\n",
      "   0.00000000e+00  1.29473684e+00  1.14842105e+01  1.45789474e+01\n",
      "   6.61052632e+00  6.52631579e-01  1.77635684e-15  6.66133815e-16]\n",
      " [ 0.00000000e+00  1.65562914e-01  4.87417219e+00  1.29668874e+01\n",
      "   1.40066225e+01  1.08807947e+01  4.41721854e+00  8.01324503e-01\n",
      "  -1.38777878e-17  1.13245033e+00  1.11059603e+01  1.16026490e+01\n",
      "   1.04503311e+01  1.26754967e+01  5.00662252e+00  5.49668874e-01\n",
      "   4.77048956e-18  1.21854305e+00  5.84768212e+00  2.47682119e+00\n",
      "   7.19867550e+00  1.14569536e+01  3.15894040e+00  9.93377483e-02\n",
      "  -1.73472348e-18  1.00662252e+00  5.41721854e+00  6.76158940e+00\n",
      "   1.24503311e+01  1.18543046e+01  4.88079470e+00 -3.46944695e-18\n",
      "   0.00000000e+00  1.49668874e+00  8.41721854e+00  1.28344371e+01\n",
      "   1.45033113e+01  1.03112583e+01  3.80132450e+00  0.00000000e+00\n",
      "  -3.29597460e-17  1.17880795e+00  5.09933775e+00  1.15496689e+01\n",
      "   1.08476821e+01  3.48344371e+00  5.56291391e-01  7.28583860e-17\n",
      "  -1.21430643e-17  1.05960265e-01  2.86754967e+00  1.26026490e+01\n",
      "   6.00662252e+00  3.37748344e-01  1.32450331e-02 -4.71844785e-16\n",
      "   0.00000000e+00  1.52317881e-01  6.11920530e+00  1.21523179e+01\n",
      "   2.31125828e+00  1.98675497e-01  3.31125828e-02 -3.33066907e-16]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Labels from the kmeans algorithm: \", kmeans.labels_)\n",
    "print(\"Lables in y_train: \", y_train)\n",
    "# print(\"Cluster centers for the kmeans alg: \", kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "BGMM = BayesianGaussianMixture(n_components = 10)\n",
    "predictions = BGMM.fit_predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 3 6 ... 1 5 6]\n",
      "[6 9 0 ... 7 5 0]\n",
      "[9 8 5 ... 1 0 9]\n"
     ]
    }
   ],
   "source": [
    "print(kmeans.labels_)\n",
    "print(predictions)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix own GNB:\n",
      "[[  0   0   0   0   0 129   0   0   0   0]\n",
      " [  0   1  39   0   0   0   0  16   0  68]\n",
      " [  0   0   2   0   8   1   0 105   0   4]\n",
      " [  3   0   0   1 113   0   4   0   0   9]\n",
      " [  0   0   5   0   0   0   6   0 116   2]\n",
      " [ 37   1   0  89   0   0   0   0   1   0]\n",
      " [  0 120   1   0   0   0   0   0   0   2]\n",
      " [  0   0   2   1   0   0 128   0   0   0]\n",
      " [ 36   2   6   5   2   0   3   1   0  72]\n",
      " [ 95   0  10   2   2   0   7   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix sklearn NBGMM:\\n%s\" % metrics.confusion_matrix(y_train, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM Algorithm according to Lab description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_NaiveEM_alg():\n",
    "    def __init__(self, n_clusters, epsilon = 1e-3):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.mu = {}\n",
    "        self.std = {}\n",
    "        self.p_C = {}\n",
    "        self.eps = epsilon\n",
    "        self.n_features = 0\n",
    "        self.r = {}\n",
    "        self.N = 0\n",
    "\n",
    "    \n",
    "    def log_prob(self, x, label):\n",
    "        prob = np.sum([-1/2*np.log(2*np.pi*self.std[label][j] + self.eps) - (x[j] - self.mu[label][j])**2/(2*self.std[label][j] + self.eps) for j in range(len(x))])\n",
    "        return prob\n",
    "    \n",
    "    def prob(self, x, label):\n",
    "        prob = sum([-1/2*np.log(2*np.pi*self.std[label][j] + self.eps) - (x[j] - self.mu[label][j])**2/(2*self.std[label][j] + self.eps) for j in range(len(x))])\n",
    "        return np.exp(prob)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def E_step(self, X):\n",
    "        for point in range(self.N):\n",
    "            nominator = sum([self.p_C[k]*self.prob(X[point,:],k) for k in range(self.n_clusters)])\n",
    "            for label in range(self.n_clusters):\n",
    "                self.r[label][point] = (self.p_C[label])*self.prob(X[point,:],label)/nominator\n",
    "        \n",
    "    def M_step(self, X):\n",
    "        for label in range(self.n_clusters):\n",
    "            r_k = sum(self.r[label])\n",
    "            top = np.zeros(self.n_features)\n",
    "            for i in range(self.N):\n",
    "                top += self.r[label][i]*np.diag(np.outer(X[i,:],X[i,:]))\n",
    "            self.p_C[label] = r_k/self.N\n",
    "            self.mu[label] = np.sum([self.r[label][i]*X[i,:] for i in range(self.N)],axis = 0)/r_k\n",
    "            self.std[label] = top/r_k - np.diag(np.outer(self.mu[label],self.mu[label]))\n",
    "        \n",
    "\n",
    "    def fit(self, X):    \n",
    "        self.n_features = X.shape[1]\n",
    "        self.N = X.shape[0]\n",
    "#         indexes = np.random.choice(self.N, 10)\n",
    "        for label in range(self.n_clusters):\n",
    "            self.r[label] = np.zeros(self.N)\n",
    "            idx = np.random.choice(self.N, 100)\n",
    "            self.mu[label] = np.mean(X[idx,:], axis = 0)\n",
    "            self.std[label] = np.var(X[idx,:], axis = 0)\n",
    "            self.p_C[label]= 1/self.n_clusters\n",
    "            \n",
    "        for i in range(100):\n",
    "            print(\"On step : \", i)\n",
    "            e_time_s = time.monotonic()\n",
    "            self.E_step(X)\n",
    "            print(\"Time to do one E-step: \", time.monotonic()-e_time_s)\n",
    "            m_time_s = time.monotonic()\n",
    "            self.M_step(X)\n",
    "            print(\"Time to do one M-step: \", time.monotonic()-m_time_s)\n",
    "#             print(\"Prior : \", self.p_C)\n",
    "    \n",
    "    def fit_cont(self,X,nbr_iters=10):\n",
    "        for i in range(nbr_iters):\n",
    "            print(\"On step : \", i)\n",
    "            e_time_s = time.monotonic()\n",
    "            self.E_step(X)\n",
    "            print(\"Time to do one E-step: \", time.monotonic()-e_time_s)\n",
    "            m_time_s = time.monotonic()\n",
    "            self.M_step(X)\n",
    "            print(\"Time to do one M-step: \", time.monotonic()-m_time_s)\n",
    "#             print(\"Prior : \", self.p_C)\n",
    "    \n",
    "        \n",
    "                    \n",
    "            \n",
    "    def predict(self, X_new):\n",
    "        yhat = np.zeros(X_new.shape[0])\n",
    "        for point in range(X_new.shape[0]):\n",
    "            yhat[point] = np.argmax([np.log(self.p_C[k] + self.eps)+self.log_prob(X_new[point,:],k) for k in range(self.n_clusters)])\n",
    "        return yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_n = x_train/16.0\n",
    "M = np.mean(x_train,axis = 0)\n",
    "STD = np.std(x_train,axis = 0)\n",
    "x_train = np.zeros(x_train.shape)\n",
    "for i in range(x_train.shape[1]):\n",
    "    if STD[i] != 0:\n",
    "        x_train_n[:,i] = np.divide((x_train[:,i]-M[i]),STD[i])\n",
    "    else:\n",
    "        x_train_n[:,i] = x_train[:,i]-M[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On step :  0\n",
      "Time to do one E-step:  35.18800000002375\n",
      "Time to do one M-step:  1.75\n",
      "On step :  1\n",
      "Time to do one E-step:  37.76600000000326\n",
      "Time to do one M-step:  1.5\n",
      "On step :  2\n",
      "Time to do one E-step:  32.60999999998603\n",
      "Time to do one M-step:  1.2959999999729916\n",
      "On step :  3\n",
      "Time to do one E-step:  31.70400000002701\n",
      "Time to do one M-step:  1.702999999979511\n",
      "On step :  4\n"
     ]
    }
   ],
   "source": [
    "nem_1 = my_NaiveEM_alg(10)\n",
    "nem_1.fit(x_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = nem.predict(x_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix own NBGMM:\n",
      "[[  0 122   0   0   0   0   0   4   0   0]\n",
      " [  2   0  25   0  24   0   6   1  28  43]\n",
      " [  0   0  40   1   0   0   9   0   0  80]\n",
      " [  0   0   2   0  19  71  13   0  10   3]\n",
      " [  0   0   0  33   0   0   5  86   4   0]\n",
      " [ 80   0   0   4  20  17   0   0   5   0]\n",
      " [  0   0  11   0   1   0   1 112   0   0]\n",
      " [  0   0   0  39   0   0   1   0  84   0]\n",
      " [  0   0   5   1  33   0  16   0  61  10]\n",
      " [  1   0   8  12  17  74   3   0  10   0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix own NBGMM:\\n%s\" % metrics.confusion_matrix(y_train, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix looks bad so lets do some plotting and change the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 5\n",
    "rows = 2\n",
    "for i in range(10):\n",
    "    img = np.reshape(nem.mu[i]*16,(8,8))\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(i)\n",
    "plt.show()\n",
    "# for i in range(10):\n",
    "#     img = np.reshape(nem.mu[i],(8,8))\n",
    "#     imgplot = plt.imshow(img)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_fix = np.zeros(len(preds))\n",
    "preds_fix[preds == 0] = 5\n",
    "preds_fix[preds == 1] = 0\n",
    "preds_fix[preds == 2] = 1\n",
    "preds_fix[preds == 3] = 4\n",
    "preds_fix[preds == 4] = 9\n",
    "preds_fix[preds == 5] = 3\n",
    "preds_fix[preds == 6] = 8\n",
    "preds_fix[preds == 7] = 6\n",
    "preds_fix[preds == 8] = 7\n",
    "preds_fix[preds == 9] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix own NBGMM:\n",
      "[[122   0   0   0   0   0   4   0   0   0]\n",
      " [  0  25  43   0   0   2   1  28   6  24]\n",
      " [  0  40  80   0   1   0   0   0   9   0]\n",
      " [  0   2   3  71   0   0   0  10  13  19]\n",
      " [  0   0   0   0  33   0  86   4   5   0]\n",
      " [  0   0   0  17   4  80   0   5   0  20]\n",
      " [  0  11   0   0   0   0 112   0   1   1]\n",
      " [  0   0   0   0  39   0   0  84   1   0]\n",
      " [  0   5  10   0   1   0   0  61  16  33]\n",
      " [  0   8   0  74  12   1   0  10   3  17]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix own NBGMM:\\n%s\" % metrics.confusion_matrix(y_train, preds_fix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.06596219875394893, 1: 0.09662574468890121, 2: 0.0726830447208384, 3: 0.07239844830869152, 4: 0.09069793962723657, 5: 0.12882654440665228, 6: 0.042221295457416236, 7: 0.16209179826394476, 8: 0.1607004078338896, 9: 0.10779257793848009}\n",
      "[0.10023866348448687, 0.1026252983293556, 0.10342084327764518, 0.09387430389817025, 0.10182975338106603, 0.10023866348448687, 0.09944311853619729, 0.09864757358790771, 0.10023866348448687, 0.09944311853619729]\n"
     ]
    }
   ],
   "source": [
    "print(nem.p_C)\n",
    "label_dist = [sum(y_train==i)/len(y_train) for i in range(10)]\n",
    "print(label_dist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
