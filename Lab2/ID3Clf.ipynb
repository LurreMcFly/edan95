{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup ToyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyData:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.attributes = {'color':['y', 'g', 'b'], 'size':['s','l'], 'shape':['r', 'i']}\n",
    "        self.classes = ('+', '-')\n",
    "\n",
    "        self.data = [('y', 's', 'r'),\n",
    "                 ('y', 's', 'r'),\n",
    "                 ('g', 's', 'i'),\n",
    "                 ('g', 'l', 'i'),\n",
    "                 ('y', 'l', 'r'),\n",
    "                 ('y', 's', 'r'),\n",
    "                 ('y', 's', 'r'),\n",
    "                 ('y', 's', 'r'),\n",
    "                 ('g', 's', 'r'),\n",
    "                 ('y', 'l', 'r'),\n",
    "                 ('y', 'l', 'r'),\n",
    "                 ('y', 'l', 'r'),\n",
    "                 ('y', 'l', 'r'),\n",
    "                 ('y', 'l', 'r'),\n",
    "                 ('y', 's', 'i'),\n",
    "                 ('y', 'l', 'i')]\n",
    "        self.target = ('+', '-', '+', '-', '+', '+', '+', '+', '-', '-', '+', '-', '-', '-', '+', '+')\n",
    "\n",
    "        self.testData = [('y', 's', 'r'),\n",
    "                 ('y', 's', 'r'),\n",
    "                 ('g', 's', 'i'),\n",
    "                 ('g', 'l', 'i'),\n",
    "                 ('y', 'l', 'r')]\n",
    "\n",
    "        self.testTarget = ('+', '-', '+', '-', '+')\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.attributes, self.classes, self.data, self.target, self.testData, self.testTarget\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement decision tree classifier based on the ID3 algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from graphviz import Digraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3DecisionTreeClassifier :\n",
    "    def __init__(self, minSamplesLeaf = 1, minSamplesSplit = 2, inequality = False) :\n",
    "        \n",
    "        self.attr_index = {}\n",
    "        self.__nodeCounter = 0\n",
    "        self.inequality = inequality\n",
    "        # the graph to visualise the tree\n",
    "        self.__dot = Digraph(comment='The Decision Tree')\n",
    "\n",
    "        # suggested attributes of the classifier to handle training parameters\n",
    "        self.__minSamplesLeaf = minSamplesLeaf\n",
    "        self.__minSamplesSplit = minSamplesSplit\n",
    "\n",
    "\n",
    "    # Create a new node in the tree with the suggested attributes for the visualisation.\n",
    "    # It can later be added to the graph with the respective function\n",
    "    def new_ID3_node(self):\n",
    "        node = {'id': self.__nodeCounter, 'label': None, 'attribute': None, 'entropy': None, 'samples': None,\n",
    "                         'classCounts': None, 'nodes': None}\n",
    "\n",
    "        self.__nodeCounter += 1\n",
    "        return node\n",
    "\n",
    "    # adds the node into the graph for visualisation (creates a dot-node)\n",
    "    def add_node_to_graph(self, node, parentid=-1):\n",
    "        nodeString = ''\n",
    "        for k in node:\n",
    "            if ((node[k] != None) and (k != 'nodes')):\n",
    "                nodeString += \"\\n\" + str(k) + \": \" + str(node[k])\n",
    "\n",
    "        self.__dot.node(str(node['id']), label=nodeString)\n",
    "        if (parentid != -1):\n",
    "            self.__dot.edge(str(parentid), str(node['id']))\n",
    "\n",
    "    # make the visualisation available\n",
    "    def make_dot_data(self) :\n",
    "        return self.__dot\n",
    "\n",
    "    # For you to fill in; Suggested function to find the best attribute to split with, given the set of\n",
    "    # remaining attributes, the currently evaluated data and target.\n",
    "    def find_split_attr(self, data,target,attributes,classes):\n",
    "        max_info_gain = None\n",
    "        for attr in attributes:\n",
    "            remaining_attr = self.removekey(attributes,attr)\n",
    "            i_gain, ent = self.info_gain(attr, data,target,attributes,classes)\n",
    "            if max_info_gain is None or i_gain > max_info_gain:\n",
    "                max_info_gain = i_gain\n",
    "                max_info_gain_attr = attr\n",
    "                \n",
    "        return max_info_gain_attr, ent\n",
    "    \n",
    "    # removes key\n",
    "    def removekey(self, d, key):\n",
    "        r = dict(d)\n",
    "        del r[key]\n",
    "        return r\n",
    "    \n",
    "    def entropy_split(self,data,target,col,val):\n",
    "        cnt = Counter()\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            if self.inequality:\n",
    "                if data[i][col] in val:\n",
    "                    cnt[target[i]] += 1\n",
    "            else:\n",
    "                if data[i][col] == val:\n",
    "                    cnt[target[i]] += 1\n",
    "            \n",
    "        n_v = len(list(cnt.elements()))\n",
    "        ent_v = 0\n",
    "        if n_v > 0:\n",
    "            for cl in classes:\n",
    "                p_x = cnt[cl]/n_v\n",
    "                if p_x != 0:\n",
    "                    ent_v += -p_x*math.log(p_x,2)\n",
    "        return ent_v, n_v\n",
    "    \n",
    "    def info_gain(self,split, data,target,attributes,classes):\n",
    "        # Calculate the entropy first\n",
    "        entropy = 0\n",
    "        cnt = Counter(target)\n",
    "        n = len(target)\n",
    "        \n",
    "        for cl in classes:\n",
    "            p_x = cnt[cl]/n\n",
    "            if p_x != 0:\n",
    "                entropy += - p_x * math.log(p_x,2)\n",
    "        \n",
    "        col = self.attr_index[split]\n",
    "        info_gain = entropy\n",
    "        for val in attributes[split]:\n",
    "            ent_v, n_v = self.entropy_split(data,target, col, val)\n",
    "            info_gain += - n_v/n*ent_v\n",
    "            \n",
    "        return info_gain, entropy\n",
    "            \n",
    "                \n",
    "    # Use this function split the data acording to the split attribute\n",
    "    # Return values are dicts with value of split attribute as keys and the data/targets as items.\n",
    "    def find_data_split(self,data,target,attributes,classes,split):\n",
    "        data_split = {}\n",
    "        target_split = {}\n",
    "        col = self.attr_index[split]\n",
    "        for vals in attributes[split]:\n",
    "            data_split[str(vals)] = []\n",
    "            target_split[str(vals)] = []\n",
    "            for i in range(len(target)):\n",
    "                if self.inequality:\n",
    "                    if data[i][col] in vals:\n",
    "                        data_split[str(vals)].append(data[i])\n",
    "                        target_split[str(vals)].append(target[i])\n",
    "                else:\n",
    "                    if data[i][col] == vals:\n",
    "                        data_split[str(vals)].append(data[i])\n",
    "                        target_split[str(vals)].append(target[i])\n",
    "                   \n",
    "        return data_split, target_split\n",
    "        \n",
    "\n",
    "    # the entry point for the recursive ID3-algorithm, you need to fill in the calls to your recursive implementation\n",
    "    def fit(self, data, target, attributes, classes, parent_id = -1):\n",
    "        if self.__nodeCounter == 0:\n",
    "            for attr in attributes:\n",
    "                self.attr_index[attr] = list(attributes.keys()).index(attr)\n",
    "                \n",
    "        node = self.new_ID3_node()\n",
    "#         self.add_node_to_graph(node)\n",
    "        cnt = Counter(target)\n",
    "        node['samples'] = len(target)\n",
    "        node['classCounts'] = cnt\n",
    "        if len(cnt) == 1:\n",
    "            node['label'] = target[0]\n",
    "            self.add_node_to_graph(node,parent_id)\n",
    "            return node\n",
    "        \n",
    "        elif len(attributes) == 0:\n",
    "            node['label'] = cnt.most_common(1)[0][0]\n",
    "            self.add_node_to_graph(node, parent_id)\n",
    "            return node\n",
    "        else:\n",
    "            split,ent = self.find_split_attr(data,target,attributes,classes)\n",
    "            node['nodes'] = {}\n",
    "            node['entropy'] = ent\n",
    "            node['attribute'] = split\n",
    "            fit_data, fit_target = self.find_data_split(data,target,attributes,classes,split)    \n",
    "            for vals in attributes[split]:\n",
    "                if len(fit_target[str(vals)]) == 0:\n",
    "                    leaf_node = self.new_ID3_node()\n",
    "                    leaf_node['label'] = cnt.most_common(1)[0][0]\n",
    "                    leaf_node['samples'] = 0\n",
    "                    self.add_node_to_graph(leaf_node,int(node['id']))\n",
    "                    node['nodes'][str(vals)] = leaf_node\n",
    "                else:\n",
    "                    remaining_attr = self.removekey(attributes, split)\n",
    "                    node['nodes'][str(vals)] = self.fit(fit_data[str(vals)],fit_target[str(vals)],remaining_attr,classes, int(node['id']))\n",
    "\n",
    "        # fill in something more sensible here..  root should become the output of the recursive tree creation\n",
    "        # root = self.new_ID3_node()\n",
    "        # self.add_node_to_graph(root)\n",
    "        self.add_node_to_graph(node, parent_id)\n",
    "        return node\n",
    "    \n",
    "\n",
    "    def predict(self, data, tree) :\n",
    "        predicted = list()\n",
    "        \n",
    "        def traverse(one_data, node):\n",
    "            if node['label'] is not None:\n",
    "                return node['label']\n",
    "            elif node['nodes'] is not None:\n",
    "                attr = node['attribute']\n",
    "                val = one_data[self.attr_index[attr]]  \n",
    "                if self.inequality:\n",
    "                    for vals in node['nodes']:\n",
    "                        if val in eval(vals):\n",
    "                            return traverse(one_data, node['nodes'][str(vals)])\n",
    "                        \n",
    "                else:\n",
    "                    return traverse(one_data,node['nodes'][str(val)])\n",
    "                \n",
    "            \n",
    "        for i in range(len(data)):\n",
    "            predicted.append(traverse(data[i],tree))\n",
    "            \n",
    "\n",
    "        # fill in something more sensible here... root should become the output of the recursive tree creation\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the ID3 classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ToyData as td\n",
    "# import ID3\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import tree, metrics, datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'label': None, 'attribute': 'size', 'entropy': 0.9886994082884974, 'samples': 16, 'classCounts': Counter({'+': 9, '-': 7}), 'nodes': {'s': {'id': 1, 'label': None, 'attribute': 'shape', 'entropy': 0.8112781244591328, 'samples': 8, 'classCounts': Counter({'+': 6, '-': 2}), 'nodes': {'r': {'id': 2, 'label': None, 'attribute': 'color', 'entropy': 0.9182958340544896, 'samples': 6, 'classCounts': Counter({'+': 4, '-': 2}), 'nodes': {'y': {'id': 3, 'label': '+', 'attribute': None, 'entropy': None, 'samples': 5, 'classCounts': Counter({'+': 4, '-': 1}), 'nodes': None}, 'g': {'id': 4, 'label': '-', 'attribute': None, 'entropy': None, 'samples': 1, 'classCounts': Counter({'-': 1}), 'nodes': None}, 'b': {'id': 5, 'label': '+', 'attribute': None, 'entropy': None, 'samples': 0, 'classCounts': None, 'nodes': None}}}, 'i': {'id': 6, 'label': '+', 'attribute': None, 'entropy': None, 'samples': 2, 'classCounts': Counter({'+': 2}), 'nodes': None}}}, 'l': {'id': 7, 'label': None, 'attribute': 'color', 'entropy': 0.9544340029249649, 'samples': 8, 'classCounts': Counter({'-': 5, '+': 3}), 'nodes': {'y': {'id': 8, 'label': None, 'attribute': 'shape', 'entropy': 0.9852281360342516, 'samples': 7, 'classCounts': Counter({'-': 4, '+': 3}), 'nodes': {'r': {'id': 9, 'label': '-', 'attribute': None, 'entropy': None, 'samples': 6, 'classCounts': Counter({'-': 4, '+': 2}), 'nodes': None}, 'i': {'id': 10, 'label': '+', 'attribute': None, 'entropy': None, 'samples': 1, 'classCounts': Counter({'+': 1}), 'nodes': None}}}, 'g': {'id': 11, 'label': '-', 'attribute': None, 'entropy': None, 'samples': 1, 'classCounts': Counter({'-': 1}), 'nodes': None}, 'b': {'id': 12, 'label': '-', 'attribute': None, 'entropy': None, 'samples': 0, 'classCounts': None, 'nodes': None}}}}}\n",
      "['+', '+', '+', '-', '-']\n"
     ]
    }
   ],
   "source": [
    "attributes, classes, data, target, data2, target2 = ToyData().get_data()\n",
    "\n",
    "id3 = ID3DecisionTreeClassifier()\n",
    "\n",
    "myTree = id3.fit(data, target, attributes, classes)\n",
    "print(myTree)\n",
    "plot = id3.make_dot_data()\n",
    "plot.render(\"testTree\")\n",
    "predicted = id3.predict(data2, myTree)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+', '+', '+', '-', '-']\n",
      "('+', '-', '+', '-', '+')\n"
     ]
    }
   ],
   "source": [
    "print(predicted)\n",
    "print(target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           +       0.67      0.67      0.67         3\n",
      "           -       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.58      0.58      0.58         5\n",
      "weighted avg       0.60      0.60      0.60         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for classifier : \\n\", metrics.classification_report(target2, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[2 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(target2, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID3 classifier with digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets,metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "# digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:10]):\n",
    "    plt.subplot(2, 5, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = len(digits.data)\n",
    "num_split = int(0.7*num_examples)\n",
    "train_features = digits.data[:num_split]\n",
    "train_labels =  digits.target[:num_split]\n",
    "test_features = digits.data[num_split:]\n",
    "test_labels = digits.target[num_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:  1257\n",
      "Number of test examples:  540\n",
      "Number of total examples: 1797\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples: \",len(train_features))\n",
    "print(\"Number of test examples: \",len(test_features))\n",
    "print(\"Number of total examples:\", len(train_features)+len(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(min_samples_leaf = 1)\n",
    "classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "id3_2 = ID3DecisionTreeClassifier()\n",
    "\n",
    "classes = [i for i in range(10)]\n",
    "attributes = {}\n",
    "for i in range(64):\n",
    "    attributes[i] = [float(j) for j in range(17)]\n",
    "my2Tree = id3_2.fit(train_features, train_labels,attributes,classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'digitsTree.pdf'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot = id3_2.make_dot_data()\n",
    "plot.render(\"digitsTree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted2 = id3_2.predict(test_features, my2Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.57      0.52        53\n",
      "           1       0.14      0.11      0.12        53\n",
      "           2       0.50      0.64      0.56        53\n",
      "           3       0.54      0.68      0.60        53\n",
      "           4       0.47      0.44      0.45        57\n",
      "           5       0.21      0.18      0.19        56\n",
      "           6       0.45      0.46      0.46        54\n",
      "           7       0.24      0.19      0.21        54\n",
      "           8       0.25      0.25      0.25        52\n",
      "           9       0.56      0.51      0.53        55\n",
      "\n",
      "    accuracy                           0.40       540\n",
      "   macro avg       0.38      0.40      0.39       540\n",
      "weighted avg       0.38      0.40      0.39       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for classifier : \\n\", metrics.classification_report(test_labels, predicted2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[30  4  0  0  4  3  8  2  1  1]\n",
      " [ 1  6  9  4  3  6  5  3  9  7]\n",
      " [ 1  4 34  5  0  2  0  2  3  2]\n",
      " [ 1  2  3 36  1  2  0  3  5  0]\n",
      " [ 6  3  1  0 25  6  9  2  1  4]\n",
      " [10  3  2  6  7 10  3  6  7  2]\n",
      " [ 5  7  0  1  5  1 25  5  4  1]\n",
      " [ 3  6  8  0  7  8  1 10  6  5]\n",
      " [ 4  7  9  2  1  6  4  6 13  0]\n",
      " [ 1  1  2 13  0  4  0  3  3 28]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(test_labels, predicted2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inequality = True\n",
    "id3_3 = ID3DecisionTreeClassifier(inequality = True)\n",
    "attributes = {}\n",
    "for i in range(64):\n",
    "    attributes[i] = list()\n",
    "    attributes[i].append([float(j) for j in range(5)])\n",
    "    attributes[i].append([float(j+5) for j in range(7)])\n",
    "    attributes[i].append([float(j+12) for j in range(5)])\n",
    "my3Tree = id3_3.fit(train_features, train_labels, attributes, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'digitsTree_DGL.pdf'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot = id3_3.make_dot_data()\n",
    "plot.render(\"digitsTree_DGL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted3 = id3_3.predict(test_features, my3Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93        53\n",
      "           1       0.66      0.77      0.71        53\n",
      "           2       0.83      0.64      0.72        53\n",
      "           3       0.85      0.75      0.80        53\n",
      "           4       0.77      0.82      0.80        57\n",
      "           5       0.76      0.79      0.77        56\n",
      "           6       0.80      0.87      0.83        54\n",
      "           7       0.72      0.80      0.75        54\n",
      "           8       0.65      0.62      0.63        52\n",
      "           9       0.88      0.78      0.83        55\n",
      "\n",
      "    accuracy                           0.78       540\n",
      "   macro avg       0.78      0.78      0.78       540\n",
      "weighted avg       0.78      0.78      0.78       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for classifier : \\n\", metrics.classification_report(test_labels, predicted3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[50  1  0  0  0  1  1  0  0  0]\n",
      " [ 0 41  0  1  3  1  2  1  3  1]\n",
      " [ 1  1 34  3  0  1  3  1  6  3]\n",
      " [ 0  2  1 40  1  4  0  3  1  1]\n",
      " [ 2  1  0  0 47  0  4  3  0  0]\n",
      " [ 0  3  1  0  3 44  0  4  1  0]\n",
      " [ 0  6  0  0  0  0 47  0  1  0]\n",
      " [ 0  1  0  1  1  4  0 43  3  1]\n",
      " [ 0  4  5  0  4  3  2  2 32  0]\n",
      " [ 1  2  0  2  2  0  0  3  2 43]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(test_labels, predicted3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy metrics (ska detta ens göras?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetrics(TP,FP,TN,FN):\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "    f1 = 2*precision*recall/(precision+recall)\n",
    "    return precision, recall, accuracy, f1\n",
    "\n",
    "def metricsReport(target, predictions,classes):\n",
    "    print(\"\\t Precision \\t\\t Recall \\t\\t accuracy \\t\\t f1-score\" )\n",
    "    for cl in classes:\n",
    "        FP = 0\n",
    "        TP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "        for i in range(len(predictions)):\n",
    "            if target[i] == predictions[i]:\n",
    "                if predictions[i] == cl:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FN += 1\n",
    "            else:\n",
    "                if predictions[i] == cl:\n",
    "                    FP += 1\n",
    "                else:\n",
    "                    TN += 1\n",
    "        pre, re, acc, f1 = getMetrics(TP,FP,TN,FN)\n",
    "        print(cl,\"\\t\",pre, \"\\t\",re, \"\\t\",acc, \"\\t\",f1)\n",
    "        \n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Precision \t\t Recall \t\t accuracy \t\t f1-score\n",
      "0 \t 0.8292682926829268 \t 0.44155844155844154 \t 0.9074074074074074 \t 0.576271186440678\n",
      "1 \t 0.7142857142857143 \t 0.06493506493506493 \t 0.8629629629629629 \t 0.11904761904761903\n",
      "2 \t 0.5454545454545454 \t 0.07792207792207792 \t 0.8592592592592593 \t 0.13636363636363635\n",
      "3 \t 0.5 \t 0.05194805194805195 \t 0.8574074074074074 \t 0.09411764705882353\n",
      "4 \t 0.1111111111111111 \t 0.012987012987012988 \t 0.8444444444444444 \t 0.023255813953488372\n",
      "5 \t 0.5714285714285714 \t 0.05194805194805195 \t 0.8592592592592593 \t 0.09523809523809525\n",
      "6 \t 0.3181818181818182 \t 0.09090909090909091 \t 0.8425925925925926 \t 0.14141414141414144\n",
      "7 \t 0.55 \t 0.14285714285714285 \t 0.8611111111111112 \t 0.2268041237113402\n",
      "8 \t 0.07692307692307693 \t 0.012987012987012988 \t 0.837037037037037 \t 0.022222222222222227\n",
      "9 \t 0.36363636363636365 \t 0.05194805194805195 \t 0.8518518518518519 \t 0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "metricsReport(test_labels, predicted3, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
