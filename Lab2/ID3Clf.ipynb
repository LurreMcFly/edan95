{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup ToyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyData:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.attributes = {'color':['y', 'g', 'b'], 'size':['s','l'], 'shape':['r', 'i']}\n",
    "        self.classes = ('+', '-')\n",
    "\n",
    "        self.data = [('y', 's', 'r'),\n",
    "                 ('y', 's', 'r'),\n",
    "                 ('g', 's', 'i'),\n",
    "                 ('g', 'l', 'i'),\n",
    "                 ('y', 'l', 'r'),\n",
    "                 ('y', 's', 'r'),\n",
    "                 ('y', 's', 'r'),\n",
    "                 ('y', 's', 'r'),\n",
    "                 ('g', 's', 'r'),\n",
    "                 ('y', 'l', 'r'),\n",
    "                 ('y', 'l', 'r'),\n",
    "                 ('y', 'l', 'r'),\n",
    "                 ('y', 'l', 'r'),\n",
    "                 ('y', 'l', 'r'),\n",
    "                 ('y', 's', 'i'),\n",
    "                 ('y', 'l', 'i')]\n",
    "        self.target = ('+', '-', '+', '-', '+', '+', '+', '+', '-', '-', '+', '-', '-', '-', '+', '+')\n",
    "\n",
    "        self.testData = [('y', 's', 'r'),\n",
    "                 ('y', 's', 'r'),\n",
    "                 ('g', 's', 'i'),\n",
    "                 ('g', 'l', 'i'),\n",
    "                 ('y', 'l', 'r')]\n",
    "\n",
    "        self.testTarget = ('+', '-', '+', '-', '+')\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.attributes, self.classes, self.data, self.target, self.testData, self.testTarget\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement decision tree classifier based on the ID3 algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from graphviz import Digraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3DecisionTreeClassifier :\n",
    "    def __init__(self, minSamplesLeaf = 1, minSamplesSplit = 2) :\n",
    "        \n",
    "        self.attr_index = {}\n",
    "        self.__nodeCounter = 0\n",
    "\n",
    "        # the graph to visualise the tree\n",
    "        self.__dot = Digraph(comment='The Decision Tree')\n",
    "\n",
    "        # suggested attributes of the classifier to handle training parameters\n",
    "        self.__minSamplesLeaf = minSamplesLeaf\n",
    "        self.__minSamplesSplit = minSamplesSplit\n",
    "\n",
    "\n",
    "    # Create a new node in the tree with the suggested attributes for the visualisation.\n",
    "    # It can later be added to the graph with the respective function\n",
    "    def new_ID3_node(self):\n",
    "        node = {'id': self.__nodeCounter, 'label': None, 'attribute': None, 'entropy': None, 'samples': None,\n",
    "                         'classCounts': None, 'nodes': None}\n",
    "\n",
    "        self.__nodeCounter += 1\n",
    "        return node\n",
    "\n",
    "    # adds the node into the graph for visualisation (creates a dot-node)\n",
    "    def add_node_to_graph(self, node, parentid=-1):\n",
    "        nodeString = ''\n",
    "        for k in node:\n",
    "            if ((node[k] != None) and (k != 'nodes')):\n",
    "                nodeString += \"\\n\" + str(k) + \": \" + str(node[k])\n",
    "\n",
    "        self.__dot.node(str(node['id']), label=nodeString)\n",
    "        if (parentid != -1):\n",
    "            self.__dot.edge(str(parentid), str(node['id']))\n",
    "\n",
    "    # make the visualisation available\n",
    "    def make_dot_data(self) :\n",
    "        return self.__dot\n",
    "\n",
    "    # For you to fill in; Suggested function to find the best attribute to split with, given the set of\n",
    "    # remaining attributes, the currently evaluated data and target.\n",
    "    def find_split_attr(self, data,target,attributes,classes):\n",
    "        max_info_gain = None\n",
    "        for attr in attributes:\n",
    "            remaining_attr = self.removekey(attributes,attr)\n",
    "            i_gain, ent = self.info_gain(attr, data,target,attributes,classes)\n",
    "            if max_info_gain is None or i_gain > max_info_gain:\n",
    "                max_info_gain = i_gain\n",
    "                max_info_gain_attr = attr\n",
    "                \n",
    "        return max_info_gain_attr, ent\n",
    "    \n",
    "    # removes key\n",
    "    def removekey(self, d, key):\n",
    "        r = dict(d)\n",
    "        del r[key]\n",
    "        return r\n",
    "    \n",
    "    def entropy_split(self,data,target,col,val):\n",
    "        cnt = Counter()\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            if data[i][col] == val:\n",
    "                cnt[target[i]] += 1\n",
    "            \n",
    "        n_v = len(list(cnt.elements()))\n",
    "        ent_v = 0\n",
    "        if n_v > 0:\n",
    "            for cl in classes:\n",
    "                p_x = cnt[cl]/n_v\n",
    "                if p_x != 0:\n",
    "                    ent_v += -p_x*math.log(p_x,2)\n",
    "        return ent_v, n_v\n",
    "    \n",
    "    def info_gain(self,split, data,target,attributes,classes):\n",
    "        # Calculate the entropy first\n",
    "        entropy = 0\n",
    "        cnt = Counter(target)\n",
    "        n = len(target)\n",
    "        \n",
    "        for cl in classes:\n",
    "            p_x = cnt[cl]/n\n",
    "            entropy += - p_x * math.log(p_x,2)\n",
    "        \n",
    "        col = self.attr_index[split]\n",
    "        info_gain = entropy\n",
    "        for val in attributes[split]:\n",
    "            ent_v, n_v = self.entropy_split(data,target, col, val)\n",
    "            info_gain += - n_v/n*ent_v\n",
    "            \n",
    "        return info_gain, entropy\n",
    "            \n",
    "                \n",
    "    # Use this function split the data acording to the split attribute\n",
    "    # Return values are dicts with value of split attribute as keys and the data/targets as items.\n",
    "    def find_data_split(self,data,target,attributes,classes,split):\n",
    "        data_split = {}\n",
    "        target_split = {}\n",
    "        col = self.attr_index[split]\n",
    "        for vals in attributes[split]:\n",
    "            data_split[vals] = []\n",
    "            target_split[vals] = []\n",
    "            for i in range(len(target)):\n",
    "                if data[i][col] == vals:\n",
    "                    data_split[vals].append(data[i])\n",
    "                    target_split[vals].append(target[i])\n",
    "                   \n",
    "        return data_split, target_split\n",
    "        \n",
    "\n",
    "    # the entry point for the recursive ID3-algorithm, you need to fill in the calls to your recursive implementation\n",
    "    def fit(self, data, target, attributes, classes, parent_id = -1):\n",
    "        if self.__nodeCounter == 0:\n",
    "            for attr in attributes:\n",
    "                self.attr_index[attr] = list(attributes.keys()).index(attr)\n",
    "                \n",
    "        node = self.new_ID3_node()\n",
    "#         self.add_node_to_graph(node)\n",
    "        cnt = Counter(target)\n",
    "        node['samples'] = len(target)\n",
    "        node['classCounts'] = cnt\n",
    "        if len(cnt) == 1:\n",
    "            node['label'] = target[0]\n",
    "            self.add_node_to_graph(node,parent_id)\n",
    "            return node\n",
    "        \n",
    "        elif len(attributes) == 0:\n",
    "            node['label'] = cnt.most_common(1)[0][0]\n",
    "            self.add_node_to_graph(node, parent_id)\n",
    "            return node\n",
    "        else:\n",
    "            split,ent = self.find_split_attr(data,target,attributes,classes)\n",
    "            node['nodes'] = {}\n",
    "            node['entropy'] = ent\n",
    "            node['attribute'] = split\n",
    "            fit_data, fit_target = self.find_data_split(data,target,attributes,classes,split)    \n",
    "            for vals in attributes[split]:\n",
    "                if len(fit_target[vals]) == 0:\n",
    "                    leaf_node = self.new_ID3_node()\n",
    "                    leaf_node['label'] = cnt.most_common(1)[0][0]\n",
    "                    leaf_node['samples'] = 0\n",
    "                    self.add_node_to_graph(leaf_node,int(node['id']))\n",
    "                    node['nodes'][vals] = leaf_node\n",
    "                else:\n",
    "                    remaining_attr = self.removekey(attributes, split)\n",
    "                    print(attributes)\n",
    "                    print(split)\n",
    "                    print(ent)\n",
    "                    print(remaining_attr)\n",
    "                    node['nodes'][vals] = self.fit(fit_data[vals],fit_target[vals],remaining_attr,classes, int(node['id']))\n",
    "\n",
    "        # fill in something more sensible here..  root should become the output of the recursive tree creation\n",
    "        # root = self.new_ID3_node()\n",
    "        # self.add_node_to_graph(root)\n",
    "        self.add_node_to_graph(node, parent_id)\n",
    "        return node\n",
    "    \n",
    "\n",
    "    def predict(self, data, tree) :\n",
    "        predicted = list()\n",
    "        \n",
    "        def traverse(one_data, node):\n",
    "            if node['label'] is not None:\n",
    "                return node['label']\n",
    "            elif node['nodes'] is not None:\n",
    "                attr = node['attribute']\n",
    "                val = one_data[self.attr_index[attr]]  \n",
    "                return traverse(one_data,node['nodes'][val])\n",
    "                \n",
    "            \n",
    "        for i in range(len(data)):\n",
    "            predicted.append(traverse(data[i],tree))\n",
    "            \n",
    "\n",
    "        # fill in something more sensible here... root should become the output of the recursive tree creation\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the ID3 classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ToyData as td\n",
    "# import ID3\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import tree, metrics, datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'color': ['y', 'g', 'b'], 'size': ['s', 'l'], 'shape': ['r', 'i']}\n",
      "size\n",
      "0.9886994082884974\n",
      "{'color': ['y', 'g', 'b'], 'shape': ['r', 'i']}\n",
      "{'color': ['y', 'g', 'b'], 'shape': ['r', 'i']}\n",
      "shape\n",
      "0.8112781244591328\n",
      "{'color': ['y', 'g', 'b']}\n",
      "{'color': ['y', 'g', 'b']}\n",
      "color\n",
      "0.9182958340544896\n",
      "{}\n",
      "{'color': ['y', 'g', 'b']}\n",
      "color\n",
      "0.9182958340544896\n",
      "{}\n",
      "{'color': ['y', 'g', 'b'], 'shape': ['r', 'i']}\n",
      "shape\n",
      "0.8112781244591328\n",
      "{'color': ['y', 'g', 'b']}\n",
      "{'color': ['y', 'g', 'b'], 'size': ['s', 'l'], 'shape': ['r', 'i']}\n",
      "size\n",
      "0.9886994082884974\n",
      "{'color': ['y', 'g', 'b'], 'shape': ['r', 'i']}\n",
      "{'color': ['y', 'g', 'b'], 'shape': ['r', 'i']}\n",
      "color\n",
      "0.9544340029249649\n",
      "{'shape': ['r', 'i']}\n",
      "{'shape': ['r', 'i']}\n",
      "shape\n",
      "0.9852281360342516\n",
      "{}\n",
      "{'shape': ['r', 'i']}\n",
      "shape\n",
      "0.9852281360342516\n",
      "{}\n",
      "{'color': ['y', 'g', 'b'], 'shape': ['r', 'i']}\n",
      "color\n",
      "0.9544340029249649\n",
      "{'shape': ['r', 'i']}\n",
      "{'id': 0, 'label': None, 'attribute': 'size', 'entropy': 0.9886994082884974, 'samples': 16, 'classCounts': Counter({'+': 9, '-': 7}), 'nodes': {'s': {'id': 1, 'label': None, 'attribute': 'shape', 'entropy': 0.8112781244591328, 'samples': 8, 'classCounts': Counter({'+': 6, '-': 2}), 'nodes': {'r': {'id': 2, 'label': None, 'attribute': 'color', 'entropy': 0.9182958340544896, 'samples': 6, 'classCounts': Counter({'+': 4, '-': 2}), 'nodes': {'y': {'id': 3, 'label': '+', 'attribute': None, 'entropy': None, 'samples': 5, 'classCounts': Counter({'+': 4, '-': 1}), 'nodes': None}, 'g': {'id': 4, 'label': '-', 'attribute': None, 'entropy': None, 'samples': 1, 'classCounts': Counter({'-': 1}), 'nodes': None}, 'b': {'id': 5, 'label': '+', 'attribute': None, 'entropy': None, 'samples': 0, 'classCounts': None, 'nodes': None}}}, 'i': {'id': 6, 'label': '+', 'attribute': None, 'entropy': None, 'samples': 2, 'classCounts': Counter({'+': 2}), 'nodes': None}}}, 'l': {'id': 7, 'label': None, 'attribute': 'color', 'entropy': 0.9544340029249649, 'samples': 8, 'classCounts': Counter({'-': 5, '+': 3}), 'nodes': {'y': {'id': 8, 'label': None, 'attribute': 'shape', 'entropy': 0.9852281360342516, 'samples': 7, 'classCounts': Counter({'-': 4, '+': 3}), 'nodes': {'r': {'id': 9, 'label': '-', 'attribute': None, 'entropy': None, 'samples': 6, 'classCounts': Counter({'-': 4, '+': 2}), 'nodes': None}, 'i': {'id': 10, 'label': '+', 'attribute': None, 'entropy': None, 'samples': 1, 'classCounts': Counter({'+': 1}), 'nodes': None}}}, 'g': {'id': 11, 'label': '-', 'attribute': None, 'entropy': None, 'samples': 1, 'classCounts': Counter({'-': 1}), 'nodes': None}, 'b': {'id': 12, 'label': '-', 'attribute': None, 'entropy': None, 'samples': 0, 'classCounts': None, 'nodes': None}}}}}\n",
      "['+', '+', '+', '-', '-']\n"
     ]
    }
   ],
   "source": [
    "attributes, classes, data, target, data2, target2 = ToyData().get_data()\n",
    "\n",
    "id3 = ID3DecisionTreeClassifier()\n",
    "\n",
    "myTree = id3.fit(data, target, attributes, classes)\n",
    "print(myTree)\n",
    "plot = id3.make_dot_data()\n",
    "plot.render(\"testTree\")\n",
    "predicted = id3.predict(data2, myTree)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes\n",
    "split = 'color'\n",
    "col = list(attributes.keys()).index(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes, classes, data, target, data2, target2 = ToyData().get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+', '+', '+', '-', '-']\n",
      "('+', '-', '+', '-', '+')\n"
     ]
    }
   ],
   "source": [
    "print(predicted)\n",
    "print(target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3DecisionTreeClassifier :\n",
    "    def __init__(self, minSamplesLeaf = 1, minSamplesSplit = 2) :\n",
    "        \n",
    "        self.attr_index = {}\n",
    "        self.__nodeCounter = 0\n",
    "\n",
    "        # the graph to visualise the tree\n",
    "        self.__dot = Digraph(comment='The Decision Tree')\n",
    "\n",
    "        # suggested attributes of the classifier to handle training parameters\n",
    "        self.__minSamplesLeaf = minSamplesLeaf\n",
    "        self.__minSamplesSplit = minSamplesSplit\n",
    "\n",
    "\n",
    "    # Create a new node in the tree with the suggested attributes for the visualisation.\n",
    "    # It can later be added to the graph with the respective function\n",
    "    def new_ID3_node(self):\n",
    "        node = {'id': self.__nodeCounter, 'label': None, 'attribute': None, 'entropy': None, 'samples': None,\n",
    "                         'classCounts': None, 'nodes': None}\n",
    "\n",
    "        self.__nodeCounter += 1\n",
    "        return node\n",
    "\n",
    "    # adds the node into the graph for visualisation (creates a dot-node)\n",
    "    def add_node_to_graph(self, node, parentid=-1):\n",
    "        nodeString = ''\n",
    "        for k in node:\n",
    "            if ((node[k] != None) and (k != 'nodes')):\n",
    "                nodeString += \"\\n\" + str(k) + \": \" + str(node[k])\n",
    "\n",
    "        self.__dot.node(str(node['id']), label=nodeString)\n",
    "        if (parentid != -1):\n",
    "            self.__dot.edge(str(parentid), str(node['id']))\n",
    "\n",
    "    # make the visualisation available\n",
    "    def make_dot_data(self) :\n",
    "        return self.__dot\n",
    "\n",
    "    # For you to fill in; Suggested function to find the best attribute to split with, given the set of\n",
    "    # remaining attributes, the currently evaluated data and target.\n",
    "    def find_split_attr(self, data,target,attributes,classes):\n",
    "        max_info_gain = None\n",
    "        max_info_gain_attr = None\n",
    "        ent = 0\n",
    "        for attr in attributes:\n",
    "            remaining_attr = self.removekey(attributes,attr)\n",
    "            i_gain, ent = self.info_gain(attr, data,target,attributes,classes)\n",
    "            if max_info_gain is None or i_gain > max_info_gain:\n",
    "                max_info_gain = i_gain\n",
    "                max_info_gain_attr = attr\n",
    "                \n",
    "        return max_info_gain_attr, ent\n",
    "    \n",
    "    # removes key\n",
    "    def removekey(self, d, key):\n",
    "        r = dict(d)\n",
    "        del r[key]\n",
    "        return r\n",
    "    \n",
    "    def entropy_split(self,data,col,val):\n",
    "        cnt = Counter()\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            if data[i][col] == val:\n",
    "                cnt[target[i]] += 1\n",
    "            \n",
    "        n_v = len(list(cnt.elements()))\n",
    "        ent_v = 0\n",
    "        if n_v > 0:\n",
    "            for cl in classes:\n",
    "                p_x = cnt[cl]/n_v\n",
    "                if p_x != 0:\n",
    "                    ent_v += -p_x*math.log(p_x,2)\n",
    "        return ent_v, n_v\n",
    "    \n",
    "    def info_gain(self,split, data,target,attributes,classes):\n",
    "        # Calculate the entropy first\n",
    "        entropy = 0\n",
    "        cnt = Counter(target)\n",
    "        n = len(target)\n",
    "        \n",
    "        for cl in classes:\n",
    "            p_x = cnt[cl]/n\n",
    "            entropy += - p_x * math.log(p_x,2)\n",
    "        \n",
    "        col = list(attributes.keys()).index(split)\n",
    "        info_gain = entropy\n",
    "        for val in attributes[split]:\n",
    "            ent_v, n_v = self.entropy_split(data, col, val)\n",
    "            info_gain += - n_v/n*ent_v\n",
    "            \n",
    "        return info_gain, entropy\n",
    "            \n",
    "                \n",
    "    # Use this function split the data acording to the split attribute\n",
    "    # Return values are dicts with value of split attribute as keys and the data/targets as items.\n",
    "    def find_data_split(self,data,target,attributes,classes,split):\n",
    "        data_split = {}\n",
    "        target_split = {}\n",
    "        key = list(split.keys())[0]\n",
    "        col = self.attr_index[key]\n",
    "        for vals in split[key]:\n",
    "            data_split[vals] = []\n",
    "            target_split[vals] = []\n",
    "            for i in range(len(target)):\n",
    "                if data[i][col] == vals:\n",
    "                    data_split[vals].append(data[i])\n",
    "                    target_split[vals].append(target[i])\n",
    "                   \n",
    "                    \n",
    "        return data_split, target_split\n",
    "    \n",
    "    def ID3(self, data, target, remaining_attr, classes):\n",
    "        node = self.new_ID3_node()\n",
    "        split_key,ent = self.find_split_attr(data,target,remaining_attr,classes)\n",
    "        split = {}\n",
    "        node['nodes'] = {}\n",
    "        node['entropy'] = ent\n",
    "        node['attribute'] = split\n",
    "        split[split_key] = remaining_attr[split_key]\n",
    "        new_remaining_attr = self.removekey(remaining_attr, split_key)\n",
    "        fit_data, fit_target = self.find_data_split(data,target,new_remaining_attr,classes,split)  \n",
    "        cnt = Counter(target)\n",
    "        node['samples'] = len(target)\n",
    "        node['classCounts'] = cnt\n",
    "        if len(cnt) == 1:\n",
    "            node['label'] = target[0]\n",
    "            return node\n",
    "        elif len(attributes) == 0:\n",
    "            node['label'] = cnt.most_common(1)[0][0]\n",
    "            return node\n",
    "        for vals in split[split_key]:\n",
    "            if len(fit_target[vals]) == 0:\n",
    "                leaf_node = self.new_ID3_node()\n",
    "                leaf_node['label'] = cnt.most_common(1)[0][0]\n",
    "                leaf_node['samples'] = 0\n",
    "                node['nodes'][vals] = leaf_node\n",
    "            else:\n",
    "                node['nodes'][vals] = self.ID3(fit_data[vals],fit_target[vals],new_remaining_attr,classes)\n",
    "\n",
    "        \n",
    "\n",
    "    # the entry point for the recursive ID3-algorithm, you need to fill in the calls to your recursive implementation\n",
    "    def fit(self, data, target, attributes, classes):\n",
    "        for attr in attributes:\n",
    "            self.attr_index[attr] = list(attributes.keys()).index(attr)\n",
    "            \n",
    "        root = self.new_ID3_node()\n",
    "        self.add_node_to_graph(root)\n",
    "        cnt = Counter(target)\n",
    "        root['samples'] = len(target)\n",
    "        root['classCounts'] = cnt\n",
    "        if len(cnt) == 1:\n",
    "            root['label'] = target[0]\n",
    "            return root\n",
    "        elif len(attributes) == 0:\n",
    "            root['label'] = cnt.most_common(1)[0][0]\n",
    "            return root\n",
    "        else:\n",
    "            self.ID3(data,target,attributes, classes)\n",
    "\n",
    "        # fill in something more sensible here..  root should become the output of the recursive tree creation\n",
    "        # root = self.new_ID3_node()\n",
    "        # self.add_node_to_graph(root)\n",
    "\n",
    "        return node\n",
    "    \n",
    "\n",
    "    def predict(self, data, tree) :\n",
    "        predicted = list()\n",
    "        \n",
    "        def traverse(one_data, node):\n",
    "            if node['label'] is not None:\n",
    "                return node['label']\n",
    "            elif node['nodes'] is not None:\n",
    "                attr = node['attribute']\n",
    "                val = one_data[self.attr_index[attr]]  \n",
    "                return traverse(one_data,node['nodes'][val])\n",
    "                \n",
    "            \n",
    "        for i in range(len(data)):\n",
    "            predicted.append(traverse(data[i],tree))\n",
    "            \n",
    "\n",
    "        # fill in something more sensible here... root should become the output of the recursive tree creation\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ToyData as td\n",
    "# import ID3\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import tree, metrics, datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-3e16adb178fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mid3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mID3DecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmyTree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mid3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mid3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-82-ea228513ae1e>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, data, target, attributes, classes)\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mattributes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;31m# fill in something more sensible here..  root should become the output of the recursive tree creation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-82-ea228513ae1e>\u001b[0m in \u001b[0;36mID3\u001b[1;34m(self, data, target, remaining_attr, classes)\u001b[0m\n\u001b[0;32m    137\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nodes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleaf_node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m                 \u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nodes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfit_target\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_remaining_attr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-82-ea228513ae1e>\u001b[0m in \u001b[0;36mID3\u001b[1;34m(self, data, target, remaining_attr, classes)\u001b[0m\n\u001b[0;32m    137\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nodes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleaf_node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m                 \u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nodes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfit_target\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_remaining_attr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-82-ea228513ae1e>\u001b[0m in \u001b[0;36mID3\u001b[1;34m(self, data, target, remaining_attr, classes)\u001b[0m\n\u001b[0;32m    137\u001b[0m                 \u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nodes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleaf_node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m                 \u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nodes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfit_target\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_remaining_attr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-82-ea228513ae1e>\u001b[0m in \u001b[0;36mID3\u001b[1;34m(self, data, target, remaining_attr, classes)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'entropy'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'attribute'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0msplit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msplit_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremaining_attr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msplit_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[0mnew_remaining_attr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremovekey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining_attr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mfit_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_data_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_remaining_attr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "attributes, classes, data, target, data2, target2 = ToyData().get_data()\n",
    "\n",
    "id3 = ID3DecisionTreeClassifier()\n",
    "\n",
    "myTree = id3.fit(data, target, attributes, classes)\n",
    "print(myTree)\n",
    "plot = id3.make_dot_data()\n",
    "plot.render(\"testTree\")\n",
    "predicted = id3.predict(data2, myTree)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
